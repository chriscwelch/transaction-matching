{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346d0f2b-7f65-4e11-ae62-14d0f6b58076",
   "metadata": {},
   "source": [
    "# Notebook to find transactions\n",
    "----\n",
    "In this notebook we'll process files from a sample data file folder to try and find a transaction.\n",
    "\n",
    "Need to add:\n",
    "- some regex to strip symbols\n",
    "- some strip to take care of any white space\n",
    "- some more dict variants\n",
    "- a method to handle the search\n",
    "\n",
    "We need to:\n",
    "- Have a process to go through a single report and find that transactions in the other files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1035311f-a97b-4641-9e9e-f3e6ec6039ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from datetime import timedelta, time, datetime, date\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7c59c3-7078-4005-893e-e1daaf83f7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Acme Trading Inc_trades_dec_2022.csv',\n",
       " 'Another Company_trades_dec_2022.csv',\n",
       " 'Glengarry Glen Ross_trades_dec_2022.csv',\n",
       " 'Joe Bloggs Investments_trades_dec_2022.csv',\n",
       " 'Trotters Independent Traders_trades_dec_2022.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('sample_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff5c3814-bc98-4881-8ec0-bd85a721d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample file\n",
    "sample_df = pd.read_csv('sample_data/Acme Trading Inc_trades_dec_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba109b3c-2f48-4e7a-b913-6d07ddce9c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>instrument</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>trade</th>\n",
       "      <th>counterparty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01T13:29:59</td>\n",
       "      <td>GB-01234567-05</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>sold to</td>\n",
       "      <td>Another Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-02T18:19:09</td>\n",
       "      <td>GB-01234567-02</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>bought from</td>\n",
       "      <td>Another Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-02T21:05:49</td>\n",
       "      <td>GB-01234567-05</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>sold to</td>\n",
       "      <td>Another Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-02T21:51:12</td>\n",
       "      <td>GB-01234567-02</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>sold to</td>\n",
       "      <td>Another Companies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-03T09:07:52</td>\n",
       "      <td>GB-01234567-03</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bought from</td>\n",
       "      <td>Another Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp      instrument  quantity  price        trade  \\\n",
       "0  2022-12-01T13:29:59  GB-01234567-05     30000   0.08      sold to   \n",
       "1  2022-12-02T18:19:09  GB-01234567-02     50000   0.02  bought from   \n",
       "2  2022-12-02T21:05:49  GB-01234567-05     90000   0.09      sold to   \n",
       "3  2022-12-02T21:51:12  GB-01234567-02     80000   0.04      sold to   \n",
       "4  2022-12-03T09:07:52  GB-01234567-03     30000   0.01  bought from   \n",
       "\n",
       "        counterparty  \n",
       "0    Another Company  \n",
       "1    Another Company  \n",
       "2    Another Company  \n",
       "3  Another Companies  \n",
       "4    Another Company  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5b056-c83a-4fc4-a462-0e6ec980a0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0061210-a0f1-47d3-8fc6-9a8692a7d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_counterparty(company_name, file_name):\n",
    "    \"\"\"\n",
    "    Function to return a DataFrame if the counterparty name \n",
    "    has been found.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_name)\n",
    "    counterparties = df.counter_party.unique()\n",
    "    if company_name in counterparties:\n",
    "        return df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d183a0c8-f0fb-449c-b82a-cc6248d51454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_dict(df):\n",
    "    \"\"\"\n",
    "    Function to return a dictionary to check that assumes all data was in good shape.\n",
    "    \"\"\"\n",
    "    dictionary = df.groupby(['timestamp', 'instrument', 'quantity',\n",
    "                   'price', 'counterparty', 'trade'])['timestamp'].count().to_dict()\n",
    "    \n",
    "    return dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6768f5-78c1-4ea2-a5bd-e1a9f330e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_dict(df):\n",
    "    \"\"\"\n",
    "    Function to return a dictionary to check that assumes timestamp was wrong.\n",
    "    \n",
    "    Here we take the minutes and seconds off of the timestamp.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['ymd'] = df.timestamp.apply(lambda x: datetime.fromisoformat(x).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    dictionary = df.groupby(['ymd', 'instrument', 'quantity',\n",
    "                   'price', 'counterparty', 'trade'])['timestamp'].count().to_dict()\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2898513-357b-44ce-8953-25f850d20a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name_is_in_cohort(df, column):\n",
    "    \"\"\"\n",
    "    Function to check is a name is within a cohort of names contained within\n",
    "    the df. This is a crude check that a spelling mistake in a name is not \n",
    "    preventing a match.\n",
    "    \n",
    "    inputs:\n",
    "    -------\n",
    "    df (DataFrame): the DataFrame that contains the column\n",
    "    column (string): the column within the DataFrame that needs to \n",
    "        be checked.\n",
    "        \n",
    "    outputs:\n",
    "    --------\n",
    "    df (DataFrame): the DataFrame with adjusted names in the\n",
    "        specified column.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_df = df.copy()\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # We check for outliers of names\n",
    "        unique_names = df[column].value_counts()\n",
    "\n",
    "        filter_value = 4\n",
    "\n",
    "        rare_names = unique_names.where(unique_names < filter_value).dropna().index.values.tolist()\n",
    "        common_names = unique_names.where(unique_names >= filter_value).dropna().index.values.tolist()\n",
    "        print(common_names)\n",
    "\n",
    "        if len(rare_names) > 0:\n",
    "            for name in rare_names:\n",
    "                # print(f\"This is a rare name: {name}\")\n",
    "                # print(\"----------\")\n",
    "                replacement_name = None\n",
    "                match_dict = {}\n",
    "\n",
    "                # Get the matches\n",
    "                for common_name in common_names:\n",
    "                    match_dict[common_name] = fuzz.ratio(name, common_name)\n",
    "\n",
    "                matches = pd.Series(match_dict)\n",
    "                # print(\"These are names to match:\")\n",
    "                # print(matches)\n",
    "                significant_matches = matches.where(matches > 70).dropna()\n",
    "                best_match = significant_matches.sort_values(ascending=False).index.values.tolist()\n",
    "\n",
    "                if len(best_match) > 0:            \n",
    "                    # print(\"\\n\")\n",
    "                    # print(\"This is the best match\")\n",
    "                    # print(best_match[0])\n",
    "                    replacement_name = best_match[0]\n",
    "                    # print(\"\\n\")\n",
    "\n",
    "                output_df[column] = np.where(output_df[column] == name, replacement_name, output_df[column])\n",
    "\n",
    "        return output_df\n",
    "    except Exception as error:\n",
    "        print(f\"Couldn't run the name matching function. Error: {error}\")\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9ae60d-b714-42c4-b1e9-aa4f78f6a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_third_dict(df):\n",
    "    \"\"\"\n",
    "    Function to perform cleaning steps and then produce a dict for searching.\n",
    "    \n",
    "    Ensure that the clean df if passed to this function to prevent passing on \n",
    "    potential errors from previous steps.\n",
    "    \n",
    "    Cols we need to clean:\n",
    "        'timestamp' - reduce to YMD\n",
    "        'instrument' - clean the string of whitespace \n",
    "        'quantity' - ensure it is a float value, no characters\n",
    "        'price' - ensure it is a float value, no characters \n",
    "        'trade' - ensure that it conforms with expected types\n",
    "        'counterparty' - clean the string of whitespace, \n",
    "            correct low risk typos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reduce to YMD\n",
    "    df['ymd'] = df.timestamp.apply(lambda x: datetime.fromisoformat(x).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Clean whitespace from the string cols\n",
    "    string_cols = ['instrument', 'trade', 'counterparty']\n",
    "    for col in string_cols:\n",
    "        df[col] = df[col].str.strip()\n",
    "        \n",
    "    float_cols = ['quantity', 'price']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].apply(lambda x: float(re.sub('[^0-9]+', \"\", str(x))))\n",
    "        \n",
    "    # Use Levenshtein distance to match some string values if wrong.\n",
    "    df = check_name_is_in_cohort(df, \"counterparty\")\n",
    "    \n",
    "    dictionary = df.groupby(['ymd', 'instrument', 'quantity',\n",
    "               'price', 'counterparty', 'trade'])['timestamp'].count().to_dict()\n",
    "    \n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ea78bf-6c61-4af9-a85e-f43c1c367370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Another Company', 'Trotters Independent Traders', 'Glengarry Glen Ross', 'Joe Bloggs Investments']\n"
     ]
    }
   ],
   "source": [
    "third_dict = get_third_dict(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec26bad-2317-45f6-95f8-ea229c3276e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "469f59f1-1022-4fa6-a819-eff9bd9fe250",
   "metadata": {},
   "source": [
    "# Match transactions to files in a folder\n",
    "----\n",
    "\n",
    "We need a function that will run through a DataFrame and find matching transactions in files within a folder.\n",
    "\n",
    "It needs to:\n",
    "- Perform a quick name check first\n",
    "- Perform more data cleaning if required\n",
    "- We want to limit the number of times that we read in a dataset to reduce memory burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f434a1dc-5f4d-48c1-b17a-224d44e2d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transaction_files(df, starting_file, folder_path, company_name):\n",
    "    \"\"\"\n",
    "    Function to append a column onto the original df that would contain the file \n",
    "    name that contained a matching transaction.\n",
    "    \n",
    "    inputs:\n",
    "    -------\n",
    "    df (DataFrame): the Dataframe that contains the transaction information to find.\n",
    "    starting_file (string): the name of the starting file that will not be searched.\n",
    "    folder_path (string): the path to the folder that contains the files to be searched.\n",
    "    \n",
    "    outputs:\n",
    "    --------\n",
    "    new_df (DataFrame): a DataFrame that is a copy of the input DataFrame with an additional\n",
    "        column that contains a filename as a string.\n",
    "    search_dict (Dictionary): nested dictionaries for checking and future use\n",
    "    matches_df (DataFrame): a DataFrame the contains the file matches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the unique counterparty names\n",
    "    df_counter_party_names = df['counterparty'].unique()\n",
    "    \n",
    "    files_to_search = os.listdir(folder_path)\n",
    "    \n",
    "    if '.ipynb_checkpoints' in files_to_search:\n",
    "        files_to_search.remove('.ipynb_checkpoints')\n",
    "    \n",
    "    search_dicts = {}\n",
    "    \n",
    "    try:\n",
    "        # Read in the data from the file, if there is no match, move onto next file\n",
    "        for input_file in files_to_search:\n",
    "            # print(input_file)\n",
    "            if input_file != starting_file:\n",
    "\n",
    "                # Read in the file.\n",
    "                this_file = pd.read_csv(f\"{folder_path}/{input_file}\")\n",
    "\n",
    "                this_file_unique_names = this_file['counterparty'].unique()\n",
    "\n",
    "                overlap = len(set(df_counter_party_names).intersection(set(this_file_unique_names)))\n",
    "\n",
    "                # If overlap is zero there are no potential matches based on \n",
    "                # the information available.\n",
    "                if overlap == 0:\n",
    "                    return\n",
    "\n",
    "                # Collect dicts\n",
    "                dict_collection = {}\n",
    "                first_dict = get_first_dict(this_file),\n",
    "                second_dict = get_second_dict(this_file),\n",
    "                third_dict = get_third_dict(this_file)\n",
    "                \n",
    "                dict_collection[\"first_dict\"] = first_dict\n",
    "                dict_collection[\"second_dict\"] = second_dict\n",
    "                dict_collection[\"third_dict\"] = third_dict\n",
    "\n",
    "                # Insert dicts into search_dicts\n",
    "                search_dicts[input_file] = dict_collection\n",
    "    except Exception as error:\n",
    "        print(f\"Couldn't process the file. Error: {error}\")\n",
    "        \n",
    "    trade_inversion = {\n",
    "        \"bought from\": \"sold to\",\n",
    "        \"sold to\": \"bought from\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    df['first_dict_lookup'] = df.apply(lambda x: (x['timestamp'], x['instrument'], x['quantity'],\n",
    "                                                 x['price']/100, company_name, trade_inversion[x['trade']]), axis=1)\n",
    "    \n",
    "\n",
    "    # Compare the dicts\n",
    "    # print(search_dicts.keys())\n",
    "    \n",
    "    matches_df = pd.DataFrame(df.first_dict_lookup, columns=['first_dict_lookup'])\n",
    "    print(matches_df.head())\n",
    "    \n",
    "    for key in search_dicts.keys():\n",
    "        file_dict = search_dicts[key]\n",
    "        first_dict = file_dict['first_dict'][0]\n",
    "        matches_df[key] = matches_df.first_dict_lookup.map(first_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return df, search_dicts, matches_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d796f030-7cc8-422f-9fc9-4caad85636f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acme Trading Inc', 'Joe Bloggs Investments', 'Trotters Independent Traders', 'Glengarry Glen Ross']\n",
      "['Trotters Independent Traders', 'Joe Bloggs Investments', 'Acme Trading Inc', 'Another Company']\n",
      "['Another Company', 'Trotters Independent Traders', 'Glengarry Glen Ross', 'Acme Trading Inc']\n",
      "['Glengarry Glen Ross', 'Another Company', 'Joe Bloggs Investments', 'Acme Trading Inc']\n",
      "                                   first_dict_lookup\n",
      "0  (2022-12-01T13:29:59, GB-01234567-05, 30000.0,...\n",
      "1  (2022-12-02T18:19:09, GB-01234567-02, 50000.0,...\n",
      "2  (2022-12-02T21:05:49, GB-01234567-05, 90000.0,...\n",
      "3  (2022-12-02T21:51:12, GB-01234567-02, 80000.0,...\n",
      "4  (2022-12-03T09:07:52, GB-01234567-03, 30000.0,...\n"
     ]
    }
   ],
   "source": [
    "new_df, search_dicts, matches_df = find_transaction_files(sample_df, \"Acme Trading Inc_trades_dec_2022.csv\",\n",
    "                                                          'sample_data', company_name=\"Acme Trading Inc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f01b14-d93e-44e0-9781-f65bd0f6ed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_dict_lookup</th>\n",
       "      <th>Another Company_trades_dec_2022.csv</th>\n",
       "      <th>Glengarry Glen Ross_trades_dec_2022.csv</th>\n",
       "      <th>Joe Bloggs Investments_trades_dec_2022.csv</th>\n",
       "      <th>Trotters Independent Traders_trades_dec_2022.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2022-12-01T13:29:59, GB-01234567-05, 30000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2022-12-02T18:19:09, GB-01234567-02, 50000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2022-12-02T21:05:49, GB-01234567-05, 90000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2022-12-02T21:51:12, GB-01234567-02, 80000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2022-12-03T09:07:52, GB-01234567-03, 30000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2022-12-03T15:08:28, GB-01234567-05, 60000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2022-12-04T04:46:11, GB-01234567-04, 20000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2022-12-04T11:32:05, GB-01234567-02, 80000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2022-12-04T19:29:36, GB-01234567-05, 10000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2022-12-06T10:27:00, GB-01234567-01, 60000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2022-12-07T13:30:10, GB-01234567-05, 80000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2022-12-07T13:39:54, GB-01234567-03, 50000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(2022-12-07T23:01:13, GB-01234567-02, 40000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(2022-12-08T04:00:14, GB-01234567-03, 80000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(2022-12-08T10:30:34, GB-01234567-02, 20000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(2022-12-09T14:52:45, GB-01234567-03, 20000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(2022-12-10T02:56:07, GB-01234567-04, 10000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(2022-12-10T07:48:07, GB-01234567-01, 40000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(2022-12-10T13:04:13, GB-01234567-02, 60000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(2022-12-10T18:49:02, GB-01234567-04, 70000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(2022-12-11T19:54:01, GB-01234567-05, 30000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(2022-12-12T22:55:28, GB-01234567-05, 70000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(2022-12-13T04:39:15, GB-01234567-02, 60000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(2022-12-13T23:23:37, GB-01234567-04, 10000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(2022-12-16T03:29:44, GB-01234567-05, 30000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(2022-12-16T06:55:24, GB-01234567-04, 50000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(2022-12-16T16:26:00, GB-01234567-02, 70000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(2022-12-17T22:16:21, GB-01234567-05, 80000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(2022-12-18T17:11:41, GB-01234567-02, 50000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(2022-12-19T13:05:19, GB-01234567-04, 40000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(2022-12-20T03:54:10, GB-01234567-03, 30000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(2022-12-20T18:04:22, GB-01234567-04, 30000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(2022-12-20T22:35:07, GB-01234567-05, 70000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(2022-12-24T15:40:52, GB-01234567-01, 10000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(2022-12-25T05:23:57, GB-01234567-05, 80000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(2022-12-25T06:47:42, GB-01234567-05, 50000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(2022-12-25T07:45:58, GB-01234567-04, 50000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(2022-12-28T09:35:26, GB-01234567-01, 10000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(2022-12-29T21:33:25, GB-01234567-01, 80000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(2022-12-30T07:24:40, GB-01234567-05, 50000.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(2022-12-30T20:51:25, GB-01234567-04, 50000.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    first_dict_lookup  \\\n",
       "0   (2022-12-01T13:29:59, GB-01234567-05, 30000.0,...   \n",
       "1   (2022-12-02T18:19:09, GB-01234567-02, 50000.0,...   \n",
       "2   (2022-12-02T21:05:49, GB-01234567-05, 90000.0,...   \n",
       "3   (2022-12-02T21:51:12, GB-01234567-02, 80000.0,...   \n",
       "4   (2022-12-03T09:07:52, GB-01234567-03, 30000.0,...   \n",
       "5   (2022-12-03T15:08:28, GB-01234567-05, 60000.0,...   \n",
       "6   (2022-12-04T04:46:11, GB-01234567-04, 20000.0,...   \n",
       "7   (2022-12-04T11:32:05, GB-01234567-02, 80000.0,...   \n",
       "8   (2022-12-04T19:29:36, GB-01234567-05, 10000.0,...   \n",
       "9   (2022-12-06T10:27:00, GB-01234567-01, 60000.0,...   \n",
       "10  (2022-12-07T13:30:10, GB-01234567-05, 80000.0,...   \n",
       "11  (2022-12-07T13:39:54, GB-01234567-03, 50000.0,...   \n",
       "12  (2022-12-07T23:01:13, GB-01234567-02, 40000.0,...   \n",
       "13  (2022-12-08T04:00:14, GB-01234567-03, 80000.0,...   \n",
       "14  (2022-12-08T10:30:34, GB-01234567-02, 20000.0,...   \n",
       "15  (2022-12-09T14:52:45, GB-01234567-03, 20000.0,...   \n",
       "16  (2022-12-10T02:56:07, GB-01234567-04, 10000.0,...   \n",
       "17  (2022-12-10T07:48:07, GB-01234567-01, 40000.0,...   \n",
       "18  (2022-12-10T13:04:13, GB-01234567-02, 60000.0,...   \n",
       "19  (2022-12-10T18:49:02, GB-01234567-04, 70000.0,...   \n",
       "20  (2022-12-11T19:54:01, GB-01234567-05, 30000.0,...   \n",
       "21  (2022-12-12T22:55:28, GB-01234567-05, 70000.0,...   \n",
       "22  (2022-12-13T04:39:15, GB-01234567-02, 60000.0,...   \n",
       "23  (2022-12-13T23:23:37, GB-01234567-04, 10000.0,...   \n",
       "24  (2022-12-16T03:29:44, GB-01234567-05, 30000.0,...   \n",
       "25  (2022-12-16T06:55:24, GB-01234567-04, 50000.0,...   \n",
       "26  (2022-12-16T16:26:00, GB-01234567-02, 70000.0,...   \n",
       "27  (2022-12-17T22:16:21, GB-01234567-05, 80000.0,...   \n",
       "28  (2022-12-18T17:11:41, GB-01234567-02, 50000.0,...   \n",
       "29  (2022-12-19T13:05:19, GB-01234567-04, 40000.0,...   \n",
       "30  (2022-12-20T03:54:10, GB-01234567-03, 30000.0,...   \n",
       "31  (2022-12-20T18:04:22, GB-01234567-04, 30000.0,...   \n",
       "32  (2022-12-20T22:35:07, GB-01234567-05, 70000.0,...   \n",
       "33  (2022-12-24T15:40:52, GB-01234567-01, 10000.0,...   \n",
       "34  (2022-12-25T05:23:57, GB-01234567-05, 80000.0,...   \n",
       "35  (2022-12-25T06:47:42, GB-01234567-05, 50000.0,...   \n",
       "36  (2022-12-25T07:45:58, GB-01234567-04, 50000.0,...   \n",
       "37  (2022-12-28T09:35:26, GB-01234567-01, 10000.0,...   \n",
       "38  (2022-12-29T21:33:25, GB-01234567-01, 80000.0,...   \n",
       "39  (2022-12-30T07:24:40, GB-01234567-05, 50000.0,...   \n",
       "40  (2022-12-30T20:51:25, GB-01234567-04, 50000.0,...   \n",
       "\n",
       "    Another Company_trades_dec_2022.csv  \\\n",
       "0                                   1.0   \n",
       "1                                   1.0   \n",
       "2                                   1.0   \n",
       "3                                   1.0   \n",
       "4                                   1.0   \n",
       "5                                   NaN   \n",
       "6                                   1.0   \n",
       "7                                   1.0   \n",
       "8                                   NaN   \n",
       "9                                   NaN   \n",
       "10                                  1.0   \n",
       "11                                  NaN   \n",
       "12                                  NaN   \n",
       "13                                  NaN   \n",
       "14                                  1.0   \n",
       "15                                  NaN   \n",
       "16                                  NaN   \n",
       "17                                  NaN   \n",
       "18                                  NaN   \n",
       "19                                  NaN   \n",
       "20                                  NaN   \n",
       "21                                  1.0   \n",
       "22                                  NaN   \n",
       "23                                  NaN   \n",
       "24                                  NaN   \n",
       "25                                  1.0   \n",
       "26                                  1.0   \n",
       "27                                  1.0   \n",
       "28                                  NaN   \n",
       "29                                  1.0   \n",
       "30                                  1.0   \n",
       "31                                  NaN   \n",
       "32                                  1.0   \n",
       "33                                  1.0   \n",
       "34                                  NaN   \n",
       "35                                  1.0   \n",
       "36                                  1.0   \n",
       "37                                  NaN   \n",
       "38                                  NaN   \n",
       "39                                  NaN   \n",
       "40                                  1.0   \n",
       "\n",
       "    Glengarry Glen Ross_trades_dec_2022.csv  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "5                                       NaN   \n",
       "6                                       NaN   \n",
       "7                                       NaN   \n",
       "8                                       NaN   \n",
       "9                                       NaN   \n",
       "10                                      NaN   \n",
       "11                                      NaN   \n",
       "12                                      NaN   \n",
       "13                                      NaN   \n",
       "14                                      NaN   \n",
       "15                                      1.0   \n",
       "16                                      1.0   \n",
       "17                                      NaN   \n",
       "18                                      NaN   \n",
       "19                                      1.0   \n",
       "20                                      NaN   \n",
       "21                                      NaN   \n",
       "22                                      1.0   \n",
       "23                                      1.0   \n",
       "24                                      1.0   \n",
       "25                                      NaN   \n",
       "26                                      NaN   \n",
       "27                                      NaN   \n",
       "28                                      1.0   \n",
       "29                                      NaN   \n",
       "30                                      NaN   \n",
       "31                                      NaN   \n",
       "32                                      NaN   \n",
       "33                                      NaN   \n",
       "34                                      NaN   \n",
       "35                                      NaN   \n",
       "36                                      NaN   \n",
       "37                                      NaN   \n",
       "38                                      NaN   \n",
       "39                                      1.0   \n",
       "40                                      NaN   \n",
       "\n",
       "    Joe Bloggs Investments_trades_dec_2022.csv  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "5                                          NaN   \n",
       "6                                          NaN   \n",
       "7                                          NaN   \n",
       "8                                          1.0   \n",
       "9                                          NaN   \n",
       "10                                         NaN   \n",
       "11                                         1.0   \n",
       "12                                         1.0   \n",
       "13                                         NaN   \n",
       "14                                         NaN   \n",
       "15                                         NaN   \n",
       "16                                         NaN   \n",
       "17                                         NaN   \n",
       "18                                         NaN   \n",
       "19                                         NaN   \n",
       "20                                         NaN   \n",
       "21                                         NaN   \n",
       "22                                         NaN   \n",
       "23                                         NaN   \n",
       "24                                         NaN   \n",
       "25                                         NaN   \n",
       "26                                         NaN   \n",
       "27                                         NaN   \n",
       "28                                         NaN   \n",
       "29                                         NaN   \n",
       "30                                         NaN   \n",
       "31                                         NaN   \n",
       "32                                         NaN   \n",
       "33                                         NaN   \n",
       "34                                         1.0   \n",
       "35                                         NaN   \n",
       "36                                         NaN   \n",
       "37                                         1.0   \n",
       "38                                         NaN   \n",
       "39                                         NaN   \n",
       "40                                         NaN   \n",
       "\n",
       "    Trotters Independent Traders_trades_dec_2022.csv  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                1.0  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                1.0  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               1.0  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               1.0  \n",
       "18                                               1.0  \n",
       "19                                               NaN  \n",
       "20                                               1.0  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23                                               NaN  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26                                               NaN  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31                                               1.0  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38                                               1.0  \n",
       "39                                               NaN  \n",
       "40                                               NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da19467-6575-40ac-8794-d928d5f9a92b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sci-env",
   "language": "python",
   "name": "data-sci-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
